# -*- coding: utf-8 -*-
"""Cyber_Modeling.ipynb

Automatically generated by Colab.

Original file is located at
 ###############################

The data is cleaned, standardized, and normalized. I wanted to break the code files so we don't have to continue to re-run the cleaning code if session crashes.
"""

import pandas as pd
import numpy as np

df = pd.read_csv("##########################")
df.head(2)

filename_dummies = pd.get_dummies(df['filename'], prefix='filename')

# Concatenate the new columns back to the original DataFrame
df_encoded = pd.concat([df, filename_dummies], axis=1)

# Optionally, drop the original 'filename' column if it's no longer needed
df_encoded.drop('filename', axis=1, inplace=True)

from sklearn.model_selection import train_test_split
# Define features and target
X = df_encoded.drop('Label', axis=1)
y = df_encoded['Label']

# Splitting the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Simple Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report


# Initialize the Logistic Regression model for multiclass using softmax
log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)

# Fit the model to the training data
log_reg.fit(X_train, y_train)

# Predict on the test data
y_pred = log_reg.predict(X_test)

# Evaluation
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))

"""Random Forest with feature importances"""

from sklearn.ensemble import RandomForestClassifier

# Initialize the Random Forest classifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf.fit(X_train, y_train)

# Get feature importance
importances = rf.feature_importances_

# Sort the features by importance
sorted_indices = np.argsort(importances)[::-1]

# Print the feature importance
for idx in sorted_indices:
    print(f"{X_train.columns[idx]}: {importances[idx]}")

"""Neural Network"""

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# Sample labels
labels = df_encoded['Label'].unique()

# Convert string labels to integers
label_encoder = LabelEncoder()
integer_encoded = label_encoder.fit_transform(labels)

# Convert integer labels to one-hot encoding
one_hot_encoded = to_categorical(integer_encoded)

# Now 'one_hot_encoded' can be used as the target data for training a neural network

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Separate features and labels
X = df_encoded.drop('Label', axis=1)
y = df_encoded['Label']

# Encode the labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_one_hot = to_categorical(y_encoded)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Ensure all feature data is float32 for TensorFlow compatibility
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

# Also ensure labels are correctly typed
y_train = y_train.astype('float32')
y_test = y_test.astype('float32')

# Neural network architecture
model = Sequential([
    Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'),  # Use scaled training data for input_dim
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(y_train.shape[1], activation='softmax')  # Correct number of output neurons
])

# Compile the model
model.compile(loss='sparse categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# Print model summary to confirm configuration
print(model.summary())

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy*100:.2f}%")

"""Unsupervised Learning / Anomoly Detection / Zero Day Attacks"""

benign_df = df[df['Label'] == 'BENIGN']
malicious_df = df[df['Label'] != 'BENIGN']

# Desired percentage of malicious instances
desired_percentage_malicious = 0.05

# Calculate the number of malicious instances needed
number_of_malicious = int(len(benign_df) * desired_percentage_malicious / (1 - desired_percentage_malicious))

# Downsample the malicious dataframe if necessary
if len(malicious_df) > number_of_malicious:
    malicious_df = malicious_df.sample(n=number_of_malicious, random_state=42)

# Combine the datasets
final_df = pd.concat([benign_df, malicious_df])

# Shuffle the dataset
final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)

# Calculate the actual percentage of malicious instances
actual_percentage_malicious = len(malicious_df) / len(final_df)
print(f"Actual percentage of malicious instances: {actual_percentage_malicious:.2%}")

final_df["Label"].unique()

X = final_df.drop('Label', axis=1)  # Drop the label to create the feature set
y = (final_df['Label'] != 'BENIGN').astype(int)  # 0 for benign, 1 for malicious
X_encoded = pd.get_dummies(X)

y.value_counts()

"""Finding best parameters for isolation forest"""

from sklearn.ensemble import IsolationForest
from sklearn.metrics import roc_auc_score

# Parameters to test
n_estimators_options = [50, 100, 200]
max_samples_options = [0.5, 0.75, 'auto']
bootstrap_options = [True, False]
contamination_options = [0.15, 0.05, 0.1]

best_score = -1
best_params = {}

# Testing combinations manually
for n_estimators in n_estimators_options:
    for max_samples in max_samples_options:
        for bootstrap in bootstrap_options:
            for contamination in contamination_options:
                clf = IsolationForest(n_estimators=n_estimators, max_samples=max_samples,
                                      bootstrap=bootstrap, contamination=contamination, random_state=42)
                clf.fit(X_encoded)

                # Obtain decision function scores or anomaly scores
                scores = clf.decision_function(X_encoded)

                # Compute AUC-ROC
                auc_roc = roc_auc_score(y, scores)

                if auc_roc > best_score:
                    best_score = auc_roc
                    best_params = {'n_estimators': n_estimators, 'max_samples': max_samples,
                                   'bootstrap': bootstrap, 'contamination': contamination}

print("Best parameters:", best_params)
print("Best AUC-ROC score:", best_score)

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.ensemble import IsolationForest
# Train Isolation Forest
clf = IsolationForest(n_estimators=50, max_samples='auto', bootstrap=True, contamination=0.15, random_state=42)
clf.fit(X_encoded)

# Make predictions (invert labels as Isolation Forest outputs -1 for outliers and 1 for inliers)
predictions = clf.predict(X_encoded)
predictions = (predictions == -1).astype(int)

# Evaluation metrics
cm = confusion_matrix(y, predictions)
acc = accuracy_score(y, predictions)
report = classification_report(y, predictions)

# Output results
print("Confusion Matrix:")
print(cm)
print("Accuracy:", acc)
print("Classification Report:")
print(report)

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.ensemble import IsolationForest
# Train Isolation Forest
clf = IsolationForest(n_estimators=50, max_samples='auto', bootstrap=True, contamination=0.05, random_state=42)
clf.fit(X_encoded)

# Make predictions (invert labels as Isolation Forest outputs -1 for outliers and 1 for inliers)
predictions = clf.predict(X_encoded)
predictions = (predictions == -1).astype(int)

# Evaluation metrics
cm = confusion_matrix(y, predictions)
acc = accuracy_score(y, predictions)
report = classification_report(y, predictions)

# Output results
print("Confusion Matrix:")
print(cm)
print("Accuracy:", acc)
print("Classification Report:")
print(report)

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Standardizing the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Calculate the Within-Cluster Sum of Squared Errors (WSS) for different number of clusters
wss = []
for i in range(1, 11):  # Testing 1 to 10 clusters
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(X_scaled)
    wss.append(kmeans.inertia_)  # inertia_ is the WSS

# Plot the Elbow Curve
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wss, marker='o')
plt.title('Elbow Method For Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('WSS')  # Within-Cluster Sum of Squares
plt.show()

# Calculate the Within-Cluster Sum of Squared Errors (WSS) for different number of clusters
wss = []
for i in range(11,15):  # Testing 1 to 10 clusters
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(X_scaled)
    wss.append(kmeans.inertia_)  # inertia_ is the WSS

# Plot the Elbow Curve
plt.figure(figsize=(10, 6))
plt.plot(range(11, 15), wss, marker='o')
plt.title('Elbow Method For Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('WSS')  # Within-Cluster Sum of Squares
plt.show()

"""Semi-supervised Learning"""

from sklearn.preprocessing import StandardScaler
X_encoded = pd.get_dummies(X)

# Split your data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Scaling features (important for most machine learning algorithms)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.decomposition import PCA

# Apply PCA for dimensionality reduction
pca = PCA(n_components=0.80)  # Retain 80% of variance
X_train_reduced = pca.fit_transform(X_train_scaled)
X_test_reduced = pca.transform(X_test_scaled)

from sklearn.semi_supervised import LabelSpreading

# Initialize the Label Spreading model
label_spread = LabelSpreading(kernel='knn', n_neighbors=7, alpha=0.2, max_iter=1000, tol=0.001)

# Fit the model on the whole training dataset
label_spread.fit(X_train_reduced, y_train)

# Making predictions
y_pred = label_spread.predict(X_test_reduced)

# Evaluate the model
from sklearn.metrics import classification_report, accuracy_score

print("Accuracy:", accuracy_score(y_test[y_test != -1], y_pred[y_test != -1]))  # Evaluate only on labeled data
print("Classification Report:\n", classification_report(y_test[y_test != -1], y_pred[y_test != -1]))

from sklearn.inspection import permutation_importance

result = permutation_importance(label_spread, X_test_reduced, y_test, n_repeats=10, random_state=42)

# Organize the importances
importances = result.importances_mean
indices = np.argsort(importances)[::-1]  # sort the feature importances in descending order

# Print the feature importance
print("Feature ranking:")
for f in range(X_test_reduced.shape[1]):
    print("%d. Feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))

"""Suspicious^"""

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier


classifier = RandomForestClassifier(n_estimators=100)
scores = cross_val_score(classifier, X_encoded, y, cv=5)  # 5-fold cross-validation
print("Accuracy scores for each fold:", scores)
print("Mean cross-validation accuracy:", scores.mean())

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Standardizing the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # Assume X is all features except 'Label'

# Applying PCA with 3 components
pca = PCA(n_components=3)
X_pca = pca.fit_transform(X_scaled)

# Applying K-Means to the PCA-reduced data
kmeans = KMeans(n_clusters=14, random_state=42)
kmeans.fit(X_pca)
labels = kmeans.labels_

# Creating a 3D plot
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot using the first three PCA components and color-coding by cluster
scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=labels, cmap='viridis', edgecolor='k', s=50)

# Adding labels to the axes
ax.set_xlabel('Principal Component 1')
ax.set_ylabel('Principal Component 2')
ax.set_zlabel('Principal Component 3')
plt.title('3D Cluster Visualization with PCA')

# Adding a color bar to show the cluster labels
cbar = plt.colorbar(scatter, ax=ax)
cbar.set_label('Cluster Label')

# Show plot
plt.show()

